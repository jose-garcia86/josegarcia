# Intro to image classification models

In the field of artificial intelligence, particularly in computer vision, image classification is a fundamental task. It involves assigning a label or category to an input image based on its visual content. the success of image classification tasks relies heavily on the architecture of the models used. Among the various types of models, **Convolutional Neural Networks (CNNs)** have proven to be highly effective. CNNs are designed to automatically and adaptively learn spatial hierarchies of features from input images through a series of layers. 

Examples of CNN architectures that have significantly advanced the field of image classification include: AlexNet, VGG, ResNet and MobileNet. Each of these models has unique characteristics and innovations that make them suitable for different applications and environments.

## Convolutional Neural Networks (CNNs)

**Convolutional Neural Networks (CNNs)** are a class of deep learning algorithms that are particularly well-suited for image recognition and classification tasks. CNNs automatically and adaptively learn spatial hierarchies of features from input images. They consist of multiple layers, such as **convolutional layers**, **pooling layers**, and **fully connected layers**, which help in detecting edges, textures, shapes, and more complex features. CNNs have been the foundation for many state-of-the-art models in computer vision.

### AlexNet

**Alex Net** is a pioneering convolutional neural network (CNN) architecture that won the **ImageNet Large Scale Visual Recognition Challenge (ILSVRC)** in 2012. Developed by Alex Kriyhevsky, Ilya Sutskever, and Geoffrey Hinton, AlexNet consists of eight layers: five convolutional layers followed by three fully connected layers. It introduced the use of **ReLU activation functions**, dropout layers to prevent overfitting, and data augmentation techniques to improve model generalization.

### VGG (Visual Geometry Group)

**VGG** refers to a series of convolutional neural network models developed by the Visual Geometry Group at the university of Oxford. The VGG architectures, such as VGG-16 and VGG-19, are known for their simplicity and uniform architecture. They use 3×3 convolutional layers stacked on top of each other, with increasing depth. This design allows the network to capture complex features while keeping the number of parameters manageable. VGG models achieved high accuracy on the ImageNet dataset and are widely used as feature extractors.

###  ResNet (Residual Networks)

**ResNet**, short for Residual Networks, is a deep learning model architecture introduced by Kaiming He and his colleagues at Microsoft Research. It addresses the issue of vanishing gradients in deep networks by introducing “residual connections”, which are shortcuts that skip one or more layers. This allows the network to learn residual functions with reference to the layer inputs, which significantly improves training efficiency and accuracy. ResNet models come in various depths, such as ResNet-50, ResNet-101, and ResNet-152, indicating the number of layers in the network.

### MobileNet

**MobileNet** is a family of lightweight deep learning models designed for efficient image classification on mobile and embedded devices. Developed by Google, MobileNet models use depthwise separable convolutions to reduce the number of parameters and computational cost. This makes them suitable for rea-time applications on devices with limited resources. MobileNet architectures include versions like MobileNetV1, V2 and V3, each providing improvements in accuracy and efficiency.